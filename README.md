# llm-behavioral-evals
 Behavioral evaluation of large language models (LLMs) under alignment stress tests. This project analyzes sycophancy, falsehood mimicry, reward tampering, and mode collapse using custom prompt datasets and open-source models (e.g., GPT-2, Mistral) on Google Colab. 
